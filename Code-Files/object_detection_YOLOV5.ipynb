{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of object_detection_YOLOV5.ipynb","provenance":[{"file_id":"1m2wlQW2lAxATwjOvNhqjv0mDSn4SLU5W","timestamp":1648710776665},{"file_id":"12Q8PYt3pTlNpQwrxM82K5btkOgsXiDwJ","timestamp":1648646218933}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4IFDHAvx7VT","executionInfo":{"status":"ok","timestamp":1645291194128,"user_tz":-330,"elapsed":25255,"user":{"displayName":"Keshav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14029300579936260948"}},"outputId":"2aa4d330-5273-42cd-f4c9-18e83b83f774"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/bin/bash: line 0: cd: drive/MyDrive/ColabNotebooks: No such file or directory\n"]}],"source":["## Drive mount\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!cd drive/MyDrive/ColabNotebooks  && ls"]},{"cell_type":"code","source":["!cd \"/content/drive/MyDrive/Colab Notebooks\"  && ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTUXAZGwzLwC","executionInfo":{"status":"ok","timestamp":1645288251973,"user_tz":-330,"elapsed":397,"user":{"displayName":"Keshav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14029300579936260948"}},"outputId":"d080da92-6a87-42ac-9573-857b0655d1b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["datasets  helpers  Train_car_person.ipynb  yolov5\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/Colab Notebooks')\n","cwd = os.getcwd()\n","print(cwd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SILu6bd90Sny","executionInfo":{"status":"ok","timestamp":1645288253743,"user_tz":-330,"elapsed":3,"user":{"displayName":"Keshav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14029300579936260948"}},"outputId":"aae3415b-5738-45f3-99b7-963f2c9f64c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"code","source":["parent_directory = ''\n","\n","\n","\n","root_directory = '/home/shalini'\n","\n","\n","parent_directory = '/content/drive/MyDrive/Colab Notebooks'\n","\n","\n","\n","datasets_directory = parent_directory+'/datasets'\n","\n","\n","dataset_name = 'car-person'\n","yoloData_directory = datasets_directory+'/'+dataset_name\n","\n","yoloData_images_directory = yoloData_directory+'/images'\n","yoloData_label_directory = yoloData_directory+'/labels'\n","\n","yoloData_images_train_directory = yoloData_images_directory+'/train'\n","yoloData_images_val_directory = yoloData_images_directory+'/val'\n","\n","yoloData_labels_train_directory = yoloData_label_directory+'/train'\n","yoloData_labels_val_directory = yoloData_label_directory+'/val'\n","\n","yolo_image_size = 640\n","\n","\n","DATA_LINK = 'https://evp-ml-data.s3.us-east-2.amazonaws.com/ml-interview/openimages-personcar/trainval.tar.gz'\n","\n","DATA_FILE_NAME = 'cars_persons'\n","\n","\n","TARGET_DOWNLOAD_FILEPATH = datasets_directory+'/'+DATA_FILE_NAME+'.tar.gz'\n","\n","unzipped_data_directory = datasets_directory+'/'+DATA_FILE_NAME+'_unzipped'\n","\n","all_images_directory = unzipped_data_directory+'/trainval/images'"],"metadata":{"id":"V1ZfBu4h0xPH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unzipped_data_directory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"5VLXEAIx2cQu","executionInfo":{"status":"ok","timestamp":1645288746514,"user_tz":-330,"elapsed":522,"user":{"displayName":"Keshav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14029300579936260948"}},"outputId":"fc70687d-d3f2-443d-9491-2a4d645507ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Colab Notebooks/datasets/cars_persons_unzipped'"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U5XYdw6M2KBD","executionInfo":{"status":"ok","timestamp":1645288840030,"user_tz":-330,"elapsed":10672,"user":{"displayName":"Keshav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14029300579936260948"}},"outputId":"651e7921-cbf4-4509-a2f6-0bd3e596a8cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 10923, done.\u001b[K\n","remote: Counting objects: 100% (7/7), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 10923 (delta 1), reused 5 (delta 1), pack-reused 10916\u001b[K\n","Receiving objects: 100% (10923/10923), 11.07 MiB | 1.91 MiB/s, done.\n","Resolving deltas: 100% (7540/7540), done.\n"]}]},{"cell_type":"code","source":["import urllib.request\n","\n","#%%\n","if not os.path.exists(datasets_directory):\n","    os.makedirs(datasets_directory)\n","\n","urllib.request.urlretrieve(DATA_LINK,TARGET_DOWNLOAD_FILEPATH)\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zyze3zgU1YK8","executionInfo":{"status":"ok","timestamp":1645288623092,"user_tz":-330,"elapsed":7958,"user":{"displayName":"Keshav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14029300579936260948"}},"outputId":"5d118152-b0e8-4012-b9cb-64a7aee66911"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/Colab Notebooks/datasets/cars_persons.tar.gz',\n"," <http.client.HTTPMessage at 0x7f7eedd47550>)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["import tarfile\n","  \n","# open file\n","with tarfile.open(TARGET_DOWNLOAD_FILEPATH)\n","  \n","# extracting file\n","file.extractall(unzipped_data_directory)\n","  \n","file.close()"],"metadata":{"id":"CuLt_g8O1pI6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import pandas as pd\n","import os\n","\n","import random\n","\n","from PIL import Image\n","\n","from tqdm import tqdm\n","\n","#%%\n","\n","def create_bb_coords(x):\n","    top_left_x,top_left_y,width,height = x\n","    x1 = top_left_x\n","    y1 = top_left_y\n","    x2 = top_left_x+width\n","    y2 = top_left_y+height\n","    return [x1,y1,x2,y2]\n","\n","def return_yolo_centre_width_height(x):\n","    top_left_x,top_left_y,width,height = x\n","    x1 = top_left_x\n","    y1 = top_left_y\n","    x2 = top_left_x+width\n","    y2 = top_left_y+height\n","    return {'centre_x':int((x1+x2)/2),\n","            'centre_y':int((y1+y2)/2),\n","            'width':width,\n","            'height':height}\n"],"metadata":{"id":"GsAyI91r2EEZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_yolo_data(train_images_df,labels_df,yoloData_images_train_directory,yoloData_labels_train_directory):\n","    \n","    for i in tqdm(range(len(train_images_df))):\n","        \n","        #% RESIZE and SAVE IMAGE\n","        image_file_name = train_images_df['file_name'][i]\n","        img = Image.open(all_images_directory+'/'+image_file_name)\n","        actual_width,actual_height = img.width,img.height\n","        img = img.resize([yolo_image_size,yolo_image_size])\n","        img.save(yoloData_images_train_directory+'/'+image_file_name)\n","        \n","        image_labels_df = labels_df[labels_df['image_id']==train_images_df['image_id'][i]].reset_index(drop=True)\n","        \n","        image_labels_df['centre_x'] /= actual_width\n","        image_labels_df['centre_y'] /= actual_height\n","        image_labels_df['width'] /= actual_width\n","        image_labels_df['height'] /= actual_height\n","        \n","               \n","        image_labels_df.drop(['image_id'],axis=1,inplace=True)\n","        \n","        # SAVE THE LABEL FILE\n","        labels_file_name = image_file_name.replace('jpg','txt')\n","        image_labels_df.to_csv(yoloData_labels_train_directory+'/'+labels_file_name,header=False,index=False,sep=' ')"],"metadata":{"id":"dTopv0gZ8qwH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(unzipped_data_directory+'/trainval/annotations/bbox-annotations.json') as json_file:\n","    data = json.load(json_file)\n","  \n","#%%\n","\n","labels_df = pd.DataFrame(data['annotations'])\n","\n","labels_df['yolov5_coords'] = labels_df['bbox'].apply(return_yolo_centre_width_height)\n","\n","labels_df = pd.concat([labels_df.drop(['yolov5_coords'], axis=1), labels_df['yolov5_coords'].apply(pd.Series)], axis=1)\n","\n","labels_df = labels_df[['image_id','category_id','centre_x','centre_y','width','height']]\n","\n","labels_df['category_id'] = labels_df['category_id'].replace({2:0})\n","\n","images_df = pd.DataFrame(data['images']).rename({'id':'image_id'},axis=1)\n","\n"],"metadata":{"id":"uJ2oHZJ38t0r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# if not os.path.exists(yoloData_all_images_directory):\n","#     os.makedirs(yoloData_all_images_directory)\n","    \n","if not os.path.exists(yoloData_images_train_directory):\n","    os.makedirs(yoloData_images_train_directory)\n","\n","if not os.path.exists(yoloData_images_val_directory):\n","    os.makedirs(yoloData_images_val_directory)\n","    \n","if not os.path.exists(yoloData_labels_train_directory):\n","    os.makedirs(yoloData_labels_train_directory)\n","\n","if not os.path.exists(yoloData_labels_val_directory):\n","    os.makedirs(yoloData_labels_val_directory)    \n","    "],"metadata":{"id":"yosy1pCd8z7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random_test_indices = random.sample(range(len(images_df)),100)\n","\n","train_images_df = images_df[~images_df.index.isin(random_test_indices)].reset_index()\n","\n","val_images_df = images_df[images_df.index.isin(random_test_indices)].reset_index()\n"],"metadata":{"id":"seeLWMu989hg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["create_yolo_data(train_images_df,labels_df,yoloData_images_train_directory,yoloData_labels_train_directory)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cr6F9hpM9BdY","executionInfo":{"status":"ok","timestamp":1645291065481,"user_tz":-330,"elapsed":600797,"user":{"displayName":"Keshav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14029300579936260948"}},"outputId":"ff257032-7e65-49a1-b2ab-8ed49ebb2038"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2139/2139 [10:00<00:00,  3.56it/s]\n"]}]},{"cell_type":"code","source":["create_yolo_data(val_images_df,labels_df,yoloData_images_val_directory,yoloData_labels_val_directory) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tIanR94x8-8Y","executionInfo":{"status":"ok","timestamp":1645291122872,"user_tz":-330,"elapsed":31004,"user":{"displayName":"Keshav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14029300579936260948"}},"outputId":"b4bd6b21-b387-44f0-8bbb-142eee6ff182"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:28<00:00,  3.46it/s]\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/yolov5')\n","cwd = os.getcwd()\n","print(cwd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9TXgjzWu9nL3","executionInfo":{"status":"ok","timestamp":1645291208353,"user_tz":-330,"elapsed":571,"user":{"displayName":"Keshav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14029300579936260948"}},"outputId":"c9e2f639-d609-4f79-f242-c744bdca8d95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/yolov5\n"]}]},{"cell_type":"code","source":["!python3 train.py --img 640 --batch 16 --epochs 10 --data car-person.yaml --weights yolov5l.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jXtrvinU9pUn","executionInfo":{"status":"ok","timestamp":1645299642958,"user_tz":-330,"elapsed":625821,"user":{"displayName":"Keshav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14029300579936260948"}},"outputId":"171a3a21-21d4-4f71-875f-da626ac5f21d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=, data=car-person.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 2022-2-19 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5l.pt to yolov5l.pt...\n","100% 89.2M/89.2M [00:12<00:00, 7.38MB/s]\n","\n","Overriding model.yaml nc=80 with nc=2\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n","  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n","  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n","  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n","  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n","  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n"," 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n"," 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n"," 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n"," 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n"," 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n","Model Summary: 468 layers, 46143679 parameters, 46143679 gradients\n","\n","Transferred 607/613 items from yolov5l.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 101 weight (no decay), 104 weight, 104 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/Colab Notebooks/datasets/car-person/labels/train' images and labels...2139 found, 0 missing, 0 empty, 0 corrupt: 100% 2139/2139 [17:12<00:00,  2.07it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Colab Notebooks/datasets/car-person/labels/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/Colab Notebooks/datasets/car-person/labels/val' images and labels...100 found, 0 missing, 0 empty, 0 corrupt: 100% 100/100 [00:50<00:00,  1.98it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Colab Notebooks/datasets/car-person/labels/val.cache\n","Plotting labels to runs/train/exp3/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.41 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp3\u001b[0m\n","Starting training for 10 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       0/9     8.93G   0.08559    0.0692   0.02179       158       640: 100% 134/134 [11:39<00:00,  5.22s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.48s/it]\n","                 all        100        733      0.567      0.595      0.561      0.249\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       1/9     9.85G   0.06269   0.05751  0.008623       121       640: 100% 134/134 [11:34<00:00,  5.18s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.38s/it]\n","                 all        100        733      0.524      0.609      0.556      0.256\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       2/9     9.85G   0.05738   0.05586   0.00675       147       640: 100% 134/134 [11:33<00:00,  5.18s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.36s/it]\n","                 all        100        733      0.641       0.61      0.648      0.291\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       3/9     9.85G   0.05493   0.05476  0.005948       126       640: 100% 134/134 [11:34<00:00,  5.18s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.36s/it]\n","                 all        100        733       0.61       0.66      0.637      0.304\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       4/9     9.85G   0.05281   0.05344  0.005875       123       640: 100% 134/134 [11:37<00:00,  5.21s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.38s/it]\n","                 all        100        733      0.761      0.646      0.712      0.364\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       5/9     9.85G   0.04864   0.05307  0.005382       150       640: 100% 134/134 [11:44<00:00,  5.26s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.37s/it]\n","                 all        100        733      0.773      0.676      0.721      0.378\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       6/9     9.85G   0.04767   0.05251  0.005178        94       640: 100% 134/134 [11:42<00:00,  5.24s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.38s/it]\n","                 all        100        733      0.771      0.674      0.726      0.409\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       7/9     9.85G   0.04448   0.05361  0.004789       137       640: 100% 134/134 [11:43<00:00,  5.25s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.38s/it]\n","                 all        100        733      0.791      0.667      0.735       0.41\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       8/9     9.85G   0.04442   0.05361  0.004459       127       640: 100% 134/134 [11:43<00:00,  5.25s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.37s/it]\n","                 all        100        733      0.774      0.658      0.725      0.405\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       9/9     9.85G   0.04149   0.05182  0.004264       116       640: 100% 134/134 [11:43<00:00,  5.25s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.37s/it]\n","                 all        100        733      0.787      0.696      0.745      0.427\n","\n","10 epochs completed in 1.980 hours.\n","Optimizer stripped from runs/train/exp3/weights/last.pt, 92.9MB\n","Optimizer stripped from runs/train/exp3/weights/best.pt, 92.9MB\n","\n","Validating runs/train/exp3/weights/best.pt...\n","Fusing layers... \n","Model Summary: 367 layers, 46113663 parameters, 0 gradients\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:12<00:00,  3.23s/it]\n","                 all        100        733      0.789      0.694      0.745      0.427\n","                 car        100        248       0.83       0.77      0.804      0.507\n","              person        100        485      0.748      0.619      0.686      0.347\n","Results saved to \u001b[1mruns/train/exp3\u001b[0m\n"]}]}]}